{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTING LIBRARIES\n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "AVAIL_GPUS = min(1, torch.cuda.device_count())\n",
    "NUM_WORKERS = int(os.cpu_count() / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING DATA MODULE\n",
    "\n",
    "class MNISTDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, data_dir=\"./data\",\n",
    "                batch_size=BATCH_SIZE, num_workers=NUM_WORKERS):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "        self.transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTenor(),\n",
    "                transforms.Normalize((0.1307,), (0.3081,)),\n",
    "            ]\n",
    "        )\n",
    "    def prepare_data(self):\n",
    "        MNIST(self.data_dir, train=True, download=True)\n",
    "        MNIST(self.data_dir, train=False, download=True)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # ASSIGNING TRAIN/VAL DATASETS\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            mnist_full = MNIST(self.data_dir, train=True, transform=self.transform)\n",
    "            self.mnist_train, self.mnist_val = random_split(mnist_full, [55000, 5000])\n",
    "\n",
    "        # ASSIGNING TESTING DATASET\n",
    "        if stage == \"test\" or stage is None:\n",
    "            self.mnist_test = MNIST(self.data_dir, train=False, transform=self.transform)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.mnist_train, batch_size=self.batch_size, num_workers=self.num_workers)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return Dataloader(self.mnist_val, batch_size=self.batch_size, num_workers=self.num_workers)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return Dataloader(self.mnist_test, batch_size=self.batch_size, num_workers=self.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DISCRIMINATOR: Detect if Data is Fake or Not -> 1 output [0, 1]\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # SIMPLE CNN\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        # FLATTEN TENSOR SO IT CAN BE FED INTO FC LAYERS\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERATOR: Generates Fake Data\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(latent_dim, 7*7*64) # [n, 256, 7, 7]\n",
    "        self.ct1 = nn.ConvTranspose2d(64, 32, 4, stride=2) # [n, 64, 16, 16]\n",
    "        self.ct2 = nn.ConvTranspose2d(32, 16, 4, stride=2) # [n, 16, 34, 34]\n",
    "        self.conv = nn.Conv2d(16, 1, kernel_size=7) # [n, 1, 28, 28]\n",
    "\n",
    "    def forward(self, x):\n",
    "        # PASS LATENT SPACE INPUT IN LINEAR LAYER AND RESHAPE\n",
    "        x = self.lin1(x)\n",
    "        x = F.relu(x)\n",
    "        x = x.view(-1, 64, 7, 7) # 256\n",
    "\n",
    "        # UPSAMPLE (TRANSPOSED CONV) 16X16 (64 FEATURE MAPS)\n",
    "        x = self.ct1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        # UPSAMPLE TO 34X34 (16 FEATURE MAPS)\n",
    "        x = self.ct2(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        # CONVOLUTION TO 28X28 (1 FEATURE MAP)\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING GENERATIVE ADVERSARIAL NETWORK CLASS\n",
    "\n",
    "class GAN(pl.LightningModule):\n",
    "    def __inti__(self, latent_dim=100, lr=0.0002):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.generator = Generator(latent_dim=self.hparams.latent_dim)\n",
    "        self.discriminator = Discriminator()\n",
    "\n",
    "        # RANDOM NOISE\n",
    "        self.validation_z = torch.randn(6, slef.hparams.latent_dim)\n",
    "\n",
    "    def foward(self, z):\n",
    "        return self.generator(z)\n",
    "\n",
    "    def adversarial_loss(self, y_hat, y):\n",
    "        return F.binary_cross_entropy(y_hat, y)\n",
    "\n",
    "    def training_step(self, batch, batch_idx, optimizer_idx):\n",
    "        real_imgs, _ = batch\n",
    "\n",
    "        # SAMPLE NOISE\n",
    "        z = torch.randn(real_imgs[0], self.hparams.latent_dim)\n",
    "        z = z.type_as(real_imgs)\n",
    "\n",
    "        # TRAIN GENERATOR: max log(Discriminator(Generator(z:random_noise)))\n",
    "        if optimizer_idx == 0:\n",
    "            fake_imgs = self(z)\n",
    "            y_hat = self.discriminator(fake_imgs)\n",
    "\n",
    "            y = torch.ones(real_imgs.size(0), 1)\n",
    "            y = y.type_as(real_imgs)\n",
    "\n",
    "            g_loss = self.adversarial_loss(y_hat, y)\n",
    "\n",
    "            log_doct = {\"g_loss\": g_loss}\n",
    "            return {\"loss\": g_loss, \"progress_bar\": log_dict, \"log\": log_dict}\n",
    "\n",
    "        # TRAIN DISCRIMINATOR: max log (D(x)) + log(1 - D(G(z)))\n",
    "        if optimizer_idx == 1:\n",
    "\n",
    "            # HOW WELL CAN IT DETECT REAL\n",
    "            y_hat_real = self.discriminator(real_imgs)\n",
    "            y_real = torch.ones(real_imgs.size(0), 1)\n",
    "            y_real = y_real.type_as(real_imgs)\n",
    "\n",
    "            real_loss = self.adversarial_loss(y_hat_real, y_real)\n",
    "            \n",
    "            # HOW WELL CAN IT DETECT FAKE\n",
    "            y_hat_fake = self.discriminator(self(z).detach())\n",
    "\n",
    "            y_fake = torch.zeros(real_imgs.size(0), 1)\n",
    "            y_fake = y_fake.type_as(real_imgs)\n",
    "\n",
    "            fake_loss = self.adversarial_loss(y_hat_fake, y_fake)\n",
    "            d_loss = (real_loss + fake_loss) / 2\n",
    "\n",
    "            log_doct = {\"d_loss\": d_loss}\n",
    "            return {\"loss\": d_loss, \"progress_bar\": log_dict, \"log\": log_dict}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        lr = self.hparams.lr\n",
    "        opt_g = torch.optim.Adam(self.generator.parameters(), lr=lr)\n",
    "        opt_d = torch.optim.Adam(self.discriminator.parameters(), lr=lr)\n",
    "        return [opt_g, opt_d], []\n",
    "\n",
    "    def plot_imgs(self):\n",
    "        z = self.validation_z.type_as(self.generator.lin1.weight)\n",
    "        sample_imgs = self(z).cpu()\n",
    "\n",
    "        print('epoch', self.current_epoch)\n",
    "        fig = plt.figure()\n",
    "        for i in range(sample_imgs.size(0)):\n",
    "            plt.subplot(2, 3, i+1)\n",
    "            plt.tight_layout()\n",
    "            plt.imshow(sample_imgs.detach()[i, 0, :, :], cmap='gray_r', interpolation='none')\n",
    "            plt.title(\"Generated Data\")\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.plot_imgs()\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
